rm(list = ls())
setwd("C:/Users/Litan/Desktop/electronidex/brand_preference")
###############
# Load packages
################
library(caret)
library(corrplot)
library(mlbench)
library(readr)
######################
# Parallel processing
######################
library(doParallel)
# Check number of cores and workers available
detectCores()
cl <- makeCluster(detectCores()-1, type='PSOCK')
registerDoParallel(cl)
CompleteResponses <- read.csv("CompleteResponses.csv", stringsAsFactors = FALSE, header=T)
# prediction/new data
SurveyIncomplete <- read.csv("SurveyIncomplete.csv", stringsAsFactors = FALSE, header=T)
CompleteResponses$elevel  <- as.ordered(CompleteResponses$elevel)
CompleteResponses$car     <- as.factor(CompleteResponses$car)
CompleteResponses$zipcode <- as.factor(CompleteResponses$zipcode)
CompleteResponses$brand   <- as.factor(CompleteResponses$brand)
str(SurveyIncomplete)
SurveyIncomplete$elevel  <- as.ordered(SurveyIncomplete$elevel)
SurveyIncomplete$car     <- as.factor(SurveyIncomplete$car)
SurveyIncomplete$zipcode <- as.factor(SurveyIncomplete$zipcode)
SurveyIncomplete$brand <- NULL
dummies1 <- dummyVars(~., CompleteResponses, fullRank = TRUE)
CompleteResponsesDV <- data.frame(predict(dummies1, CompleteResponses))
names(CompleteResponsesDV)[names(CompleteResponsesDV)=="brand.1"] <- "brand"
CompleteResponsesDV$brand <- as.factor(CompleteResponsesDV$brand)
str(CompleteResponsesDV)
dummies2 <- dummyVars(~., SurveyIncomplete, fullRank = TRUE)
SurveyIncompleteDV <- data.frame(predict(dummies2, SurveyIncomplete))
str(SurveyIncompleteDV)
# make polynomial features
#trainSetDVSP <-
# Split into training/val set and test set. We will use k-fold cross validation
# when training, so training and validation examples will both be pulled from
inTraining <- createDataPartition(CompleteResponsesDV$brand, p=0.8, list=FALSE)
trainSetDV <- CompleteResponsesDV[inTraining,]
testSetDV <- CompleteResponsesDV[-inTraining,]
# scale features
scaleParamsTrain <- preProcess(trainSetDV[, c(1,2,3,31)],
method = c("center", "scale"))
print(scaleParamsTrain)
trainSetDVS <- predict(scaleParamsTrain, trainSetDV)
testSetDVS <- predict(scaleParamsTrain, testSetDV) # scaled with trainSet params
predictionSetDVS <- predict(scaleParamsTrain, SurveyIncompleteDV) # scaled with trainSet params
rfFitControl <- trainControl(method = "cv", number = 10,
summaryFunction = defaultSummary)
startTime <- Sys.time()
rfFit <- train(x = trainSetDVS[ ,1:34], y = trainSetDVS$brand,
method="rf",
trControl=rfFitControl,
tuneLength = 10)
endTime <- Sys.time()
rfFitRunTime <- endTime - startTime
rfFitRunTime
print(rfFit)
print(rfFit$finalModel)
View(testSetDVS)
View(trainSetDVS)
rm(list = ls())
setwd("C:/Users/Litan/Desktop/electronidex/brand_preference")
###############
# Load packages
################
library(caret)
library(corrplot)
library(mlbench)
library(readr)
######################
# Parallel processing
######################
library(doParallel)
# Check number of cores and workers available
detectCores()
cl <- makeCluster(detectCores()-1, type='PSOCK')
registerDoParallel(cl)
CompleteResponses <- read.csv("CompleteResponses.csv", stringsAsFactors = FALSE, header=T)
# prediction/new data
SurveyIncomplete <- read.csv("SurveyIncomplete.csv", stringsAsFactors = FALSE, header=T)
is.na(SurveyIncomplete)
anyNA(SurveyIncomplete)
anyNA(CompleteResponses)
str(CompleteResponses)
str(CompleteResponses)
CompleteResponses$elevel  <- as.ordered(CompleteResponses$elevel)
CompleteResponses$car     <- as.factor(CompleteResponses$car)
CompleteResponses$zipcode <- as.factor(CompleteResponses$zipcode)
CompleteResponses$brand   <- as.factor(CompleteResponses$brand)
SurveyIncomplete$elevel  <- as.ordered(SurveyIncomplete$elevel)
SurveyIncomplete$car     <- as.factor(SurveyIncomplete$car)
SurveyIncomplete$zipcode <- as.factor(SurveyIncomplete$zipcode)
SurveyIncomplete$brand <- NULL
str(CompleteResponses)
str(SurveyIncomplete)
inTraining <- createDataPartition(CompleteResponses$brand, p=0.8, list=FALSE)
trainSet <- CompleteResponses[inTraining,]
testSet <- CompleteResponses[-inTraining,]
View(trainSet)
scaleParamsTrain <- preProcess(trainSet[, c(1,2,6)],
method = c("center", "scale"))
print(scaleParamsTrain)
trainSetS <- predict(scaleParamsTrain, trainSet)
testSetS <- predict(scaleParamsTrain, testSet) # scaled with trainSet params
predictionSetS <- predict(scaleParamsTrain, SurveyIncomplete) # scaled with trainSet params
View(predictionSetS)
View(testSetS)
View(trainSetS)
rfFitControl <- trainControl(method = "cv", number = 10,
summaryFunction = defaultSummary)
modelLookup("rf")
startTime <- Sys.time()
rfFit <- train(x = trainSetDVS[ ,1:34], y = trainSetDVS$brand,
method="rf",
trControl=rfFitControl,
tuneLength = 10)
endTime <- Sys.time()
rfFitRunTime <- endTime - startTime
rfFitRunTime
trainSetS[ ,1:6]
y = trainSetS$brand
trainSetS$brand
startTime <- Sys.time()
rfFit <- train(x = trainSetS[ ,1:6], y = trainSetS$brand,
method="rf",
trControl=rfFitControl,
tuneLength = 10)
endTime <- Sys.time()
rfFitRunTime <- endTime - startTime
print(rfFit)
print(rfFit$finalModel)
print(rfFit)
print(rfFit$finalModel)
print(rfFit)
print(rfFit$finalModel)
trainPred <- predict(rfFit, trainSetS[ ,1:6])
confusionMatrix(trainPred, trainSetS$brand)
ggplot(rfFit)
ggplot(rfFit, metric = "Kappa")
testPred <- predict(rfFit, testSetS[ ,1:6])
confusionMatrix(testPred, testSetS$brand)
print(rfFit$finalModel)
print(rfFit)
trainPred <- predict(rfFit, trainSetS[ ,1:6])
trainPred
confusionMatrix(trainPred, trainSetS$brand)
uh < trainSetS$brand
uh <- trainSetS$brand
uh
uh[3]
uh[3] = 1
confusionMatrix(trainPred, uh)
getTrainPerf(rfFit)
print(rfFit$finalModel)
print(rfFit)
getTrainPerf(rfFit)
print(rfFit$finalModel)
print(rfFit)
ggplot(rfFit)
ggplot(rfFit, metric = "Kappa")
confusionMatrix(trainPred, trainSetS$brand)
rfFit$finalModel$mtry
rfFit$pred
print(rfFit$finalModel)
confusionMatrix(data = trainPred, reference = trainSetS$brand)
confusionMatrix(data = trainPred, reference = trainSetS$brand)
trainPred <- predict(rfFit, trainSetS[ ,1:6])
confusionMatrix(data = trainPred, reference = trainSetS$brand)
print(rfFit)
print(rfFit$finalModel) # confusion matrix in finalModel is based on the 500
confusionMatrix(rfFit)
confusionMatrix(rfFit, norm = "none")
print(rfFit)
confusionMatrix(rfFit, norm = "none")
testPred <- predict(rfFit, testSetS[ ,1:6])
confusionMatrix(data = testPred, reference = testSetS$brand)
saveRDS(rfFit, "rfFit.rds")
loadRDS("rfFit.rds")
testSetS[ ,1:6]
varImp(rfFit)
predictors(rfFit)
resamplingResults <- resamples(list(rf=rfFit))
postResample(testPred, testSetS$brand)
confusionMatrix(data = testPred, reference = testSetS$brand)
View(trainSetS)
View(testSetS)
write.csv(trainSetS, "rf_trainSetS.csv", row.names = FALSE)
write.csv(testSetS, "rf_testSetS.csv", row.names = FALSE)
print(rfFit)
startTime <- Sys.time()
#rfFit <- train(x = trainSetS[ ,1:6], y = trainSetS$brand,
#               method="rf",
#               trControl=rfFitControl,
#               tuneLength = 5)
rfFit <- train(x = trainSetS[ ,1:6], y = trainSetS$brand,
method = "ranger",
trControl = rfFitControl)
rfFitRunTime
print(rfFit)
confusionMatrix(rfFit, norm = "none") # confusion matrix for the hold-out samples
ggplot(rfFit)
trainPred <- predict(rfFit, trainSetS[ ,1:6])
confusionMatrix(data = trainPred, reference = trainSetS$brand)
modelLookup("ranger")
rangerGrid <- expand.grid(mtry = c(2,4,6,8,10),
splitrule = c("gini", "extratrees"),
min.node.size = c(1,3,5))
nrow(rangerGrid)
startTime <- Sys.time()
#rfFit <- train(x = trainSetS[ ,1:6], y = trainSetS$brand,
#               method="rf",
#               trControl=rfFitControl,
#               tuneLength = 5)
rfFit <- train(x = trainSetS[ ,1:6], y = trainSetS$brand,
method = "ranger",
trControl = rfFitControl,
tuneGrid = rangerGrid)
endTime <- Sys.time()
rfFitRunTime <- endTime - startTime
rfFitRunTime
print(rfFit)
confusionMatrix(rfFit, norm = "none") # confusion matrix for the hold-out samples
print(rfFit$finalModel) # confusion matrix in finalModel is based on the 500
trainPred <- predict(rfFit, trainSetS[ ,1:6])
confusionMatrix(data = trainPred, reference = trainSetS$brand)
print(rfFit)
testPred <- predict(rfFit, testSetS[ ,1:6])
confusionMatrix(data = testPred, reference = testSetS$brand)
rangerGrid <- expand.grid(mtry = c(2,4,6,8,10),
splitrule = c("gini"),
min.node.size = c(1,3,5,7,9))
startTime <- Sys.time()
#rfFit <- train(x = trainSetS[ ,1:6], y = trainSetS$brand,
#               method="rf",
#               trControl=rfFitControl,
#               tuneLength = 5)
rfFit <- train(x = trainSetS[ ,1:6], y = trainSetS$brand,
method = "ranger",
trControl = rfFitControl,
tuneGrid = rangerGrid)
rangerGrid <- expand.grid(mtry = c(2,4,6,8,10),
splitrule = c("gini"),
min.node.size = c(7,9))
nrow(rangerGrid)
# Try different sets of hyperparameters, pick the best set based on best
# cross-validated accuracy (and kappa), and fit the final model to all the
# training data using the optimal hyperparamter set.
startTime <- Sys.time()
#rfFit <- train(x = trainSetS[ ,1:6], y = trainSetS$brand,
#               method="rf",
#               trControl=rfFitControl,
#               tuneLength = 5)
rfFit <- train(x = trainSetS[ ,1:6], y = trainSetS$brand,
method = "ranger",
trControl = rfFitControl,
tuneGrid = rangerGrid)
endTime <- Sys.time()
rfFitRunTime <- endTime - startTime
rangerGrid <- expand.grid(mtry = c(2,4,6,8,10),
splitrule = c("gini"),
min.node.size = c(7,9))
startTime <- Sys.time()
#rfFit <- train(x = trainSetS[ ,1:6], y = trainSetS$brand,
#               method="rf",
#               trControl=rfFitControl,
#               tuneLength = 5)
rfFit <- train(x = trainSetS[ ,1:6], y = trainSetS$brand,
method = "ranger",
trControl = rfFitControl,
tuneGrid = rangerGrid)
endTime <- Sys.time()
rfFitRunTime <- endTime - startTime
print(rfFit)
confusionMatrix(rfFit, norm = "none") # confusion matrix for the hold-out samples
trainPred <- predict(rfFit, trainSetS[ ,1:6])
confusionMatrix(data = trainPred, reference = trainSetS$brand)
testPred <- predict(rfFit, testSetS[ ,1:6])
confusionMatrix(data = testPred, reference = testSetS$brand)
saveRDS(rfFit, "rangerFit.rds")
varImp(rfFit) # most important features
print(rfFit)
confusionMatrix(rfFit, norm = "none") # confusion matrix for the hold-out samples
ggplot(rfFit)
print(rfFit$finalModel) # confusion matrix in finalModel is based on the 500
print(rfFit$finalModel) # confusion matrix in finalModel is based on the 500
confusionMatrix(rfFit, norm = "none") # confusion matrix for the hold-out samples
print(rfFit$finalModel)
confusionMatrix(data = trainPred, reference = trainSetS$brand)
testPred <- predict(rfFit, testSetS[ ,1:6])
confusionMatrix(data = testPred, reference = testSetS$brand)
print(rfFit$finalModel)
rangerFit <- readRDS("rangerFit.rds")
predictionPred <- predict(rangerFit, predictionSetS)
predictionPred
summary(predictionPred)
View(predictionSetS)
predictionSetS$brand <- predictionPred
View(predictionSetS)
View(SurveyIncomplete)
SurveyIncomplete$brand <- predictionPred
View(SurveyIncomplete)
write.csv(SurveyIncomplete, "SurveyComplete")
print(rangerFit$finalModel)
rm(list = ls())
setwd("C:/Users/Litan/Desktop/electronidex/brand_preference")
library(caret)
library(corrplot)
library(mlbench)
library(readr)
library(doParallel)
# Check number of cores and workers available
detectCores()
cl <- makeCluster(detectCores()-1, type='PSOCK')
registerDoParallel(cl)
CompleteResponses <- read.csv("CompleteResponses.csv", stringsAsFactors = FALSE, header=T)
# prediction/new data
SurveyIncomplete <- read.csv("SurveyIncomplete.csv", stringsAsFactors = FALSE, header=T)
str(CompleteResponses)
CompleteResponses$elevel  <- as.ordered(CompleteResponses$elevel)
CompleteResponses$car     <- as.factor(CompleteResponses$car)
CompleteResponses$zipcode <- as.factor(CompleteResponses$zipcode)
CompleteResponses$brand   <- as.factor(CompleteResponses$brand)
SurveyIncomplete$elevel  <- as.ordered(SurveyIncomplete$elevel)
SurveyIncomplete$car     <- as.factor(SurveyIncomplete$car)
SurveyIncomplete$zipcode <- as.factor(SurveyIncomplete$zipcode)
SurveyIncomplete$brand <- NULL
inTraining <- createDataPartition(CompleteResponses$brand, p=0.8, list=FALSE)
trainSet <- CompleteResponses[inTraining,]
testSet <- CompleteResponses[-inTraining,]
View(trainSet)
scaleParamsTrain <- preProcess(trainSet[, c(1,2,6)],
method = c("center", "scale"))
print(scaleParamsTrain)
trainSetS <- predict(scaleParamsTrain, trainSet)
testSetS <- predict(scaleParamsTrain, testSet) # scaled with training set means and std. devs.
predictionSetS <- predict(scaleParamsTrain, SurveyIncomplete) # scaled with train set means and std. devs.
View(trainSetS)
write.csv(trainSetS, "rf_trainSetS.csv", row.names = FALSE)
write.csv(testSetS, "rf_testSetS.csv", row.names = FALSE)
write.csv(predictionSetS, "rf_predictionSetS.csv", row.names = FALSE)
rangerFitControl <- trainControl(method = "cv", number = 10,
summaryFunction = defaultSummary)
modelLookup("ranger")
rangerGrid <- expand.grid(mtry = c(2,4,6,8,10),
splitrule = c("gini"),
min.node.size = c(7,9))
nrow(rangerGrid)
print(rangerFit)
rangerFit <- readRDS("rangerFit.rds")
print(rangerFit)
confusionMatrix(rangerFit, norm = "none") # confusion matrix for the hold-out samples
ggplot(rangerFit)
ggplot(rangerFit, metric = "Kappa")
varImp(rangerFit) # most important features
print(rangerFit$finalModel)
trainPred <- predict(rangerFit, trainSetS[ ,1:6])
confusionMatrix(data = trainPred, reference = trainSetS$brand)
testPred <- predict(rangerFit, testSetS[ ,1:6])
confusionMatrix(data = testPred, reference = testSetS$brand)
write.csv(SurveyIncomplete, "results.csv")
summary(predictionPred)
predictionPred <- predict(rangerFit, predictionSetS)
SurveyIncomplete$brand <- predictionPred
write.csv(SurveyIncomplete, "results.csv")
summary(predictionPred)
stopCluster(cl)
