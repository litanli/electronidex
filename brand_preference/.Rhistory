rm(list = ls())
setwd("C:/Users/Litan/Desktop/electronidex/brand_preference")
###############
# Load packages
################
library(caret)
library(corrplot)
library(mlbench)
library(readr)
CompleteResponses <- read.csv("CompleteResponses.csv", stringsAsFactors = FALSE, header=T)
# prediction/new data
SurveyIncomplete <- read.csv("SurveyIncomplete.csv", stringsAsFactors = FALSE, header=T)
CompleteResponses$elevel  <- as.ordered(CompleteResponses$elevel)
CompleteResponses$car     <- as.factor(CompleteResponses$car)
CompleteResponses$zipcode <- as.factor(CompleteResponses$zipcode)
CompleteResponses$brand   <- as.factor(CompleteResponses$brand)
str(SurveyIncomplete)
SurveyIncomplete$elevel  <- as.ordered(SurveyIncomplete$elevel)
SurveyIncomplete$car     <- as.factor(SurveyIncomplete$car)
SurveyIncomplete$zipcode <- as.factor(SurveyIncomplete$zipcode)
# remove label column from prediction/new data - shouldn't be there
SurveyIncomplete$brand <- NULL
str(CompleteResponses)
str(SurveyIncomplete)
# Then create dummy variables. No linear dependencies: FullRank = TRUE
dummies1 <- dummyVars(~., CompleteResponses, fullRank = TRUE)
CompleteResponsesDV <- data.frame(predict(dummies1, CompleteResponses))
names(CompleteResponsesDV)[names(CompleteResponsesDV)=="brand.1"] <- "brand"
CompleteResponsesDV$brand <- as.factor(CompleteResponsesDV$brand)
str(CompleteResponsesDV)
dummies2 <- dummyVars(~., SurveyIncomplete, fullRank = TRUE)
SurveyIncompleteDV <- data.frame(predict(dummies2, SurveyIncomplete))
str(SurveyIncompleteDV)
# Split into training/val set and test set. We will use k-fold cross validation
# when training, so training and validation examples will both be pulled from
# trainSet
inTraining <- createDataPartition(CompleteResponsesDV$brand, p=0.8, list=FALSE)
trainSet <- CompleteResponsesDV[inTraining,]
testSet <- CompleteResponsesDV[-inTraining,]
# scale features
scaleParamsTrain <- preProcess(trainSet[, c(1,2,34)],
method = c("center", "scale"))
print(scaleParamsTrain)
trainSetS <- predict(scaleParamsTrain, trainSet)
testSetS <- predict(scaleParamsTrain, testSet) # scaled with trainSet params
predictionSetS <- predict(scaleParamsTrain, SurveyIncompleteDV) # scaled with trainSet params
#################
# Train model(s)
#################
## ------- Regularized Logistic Regression ------- ##
# 10-fold cross validation.
# summaryFunction: classification -> Data not skewed -> Use accuracy and kappa
regLogisticFitControl <- trainControl(method = "cv", number = 10,
summaryFunction = defaultSummary)
# hyperparameter values to try
modelLookup("regLogistic")
regLogisticGrid <- expand.grid(cost = c(0,0.03,0.1,0.3,1,3,10),
loss = c("L1", "L2_dual", "L2_primal"),
epsilon = c(0.01))
nrow(regLogisticGrid)
startTime <- Sys.time()
regLogisticFit2 <- train(x = CompleteResponses[ ,1:6], y = CompleteResponses[ ,7],
method="regLogistic",
trControl=regLogisticFitControl)
endTime <- Sys.time()
regLogisticFit2RunTime <- endTime - startTime
regLogisticFit2RunTime
print(regLogisticFit2)
rm(list = ls())
setwd("C:/Users/Litan/Desktop/electronidex/brand_preference")
###############
# Load packages
################
library(caret)
library(corrplot)
library(mlbench)
library(readr)
CompleteResponses <- read.csv("CompleteResponses.csv", stringsAsFactors = FALSE, header=T)
# prediction/new data
SurveyIncomplete <- read.csv("SurveyIncomplete.csv", stringsAsFactors = FALSE, header=T)
hist(SurveyIncomplete$salary)
hist(SurveyIncomplete$age)
hist(SurveyIncomplete$elevel)
hist(SurveyIncomplete$car)
hist(SurveyIncomplete$zipcode)
hist(SurveyIncomplete$credit)
qqnorm(SurveyIncomplete$credit) #normal quantile plot.
qqplot(SurveyIncomplete$salary, SurveyIncomplete$age, plot.it = TRUE) # q-q plot.
# check for missing values
anyNA(SurveyIncomplete)
is.na(SurveyIncomplete)
##########################################
# Preprocess Data and Feature Engineering
##########################################
# Encode all categorical variables to numeric data as dummy
# variables.
# First change categorical variables to factor/ordered. See http://appliedpredictivemodeling.com/blog/2013/10/23/the-basics-of-encoding-categorical-data-for-predictive-models
# for a discussion on encoding factor vs ordinal.
# Change elvel to ordered. We'll attempt to capture underlying patterns between
# elevel and brand using polynomial feature terms. Treat other categorical
# variables as nominal.
str(CompleteResponses)
CompleteResponses$elevel  <- as.ordered(CompleteResponses$elevel)
CompleteResponses$car     <- as.factor(CompleteResponses$car)
CompleteResponses$zipcode <- as.factor(CompleteResponses$zipcode)
CompleteResponses$brand   <- as.factor(CompleteResponses$brand)
str(SurveyIncomplete)
SurveyIncomplete$elevel  <- as.ordered(SurveyIncomplete$elevel)
SurveyIncomplete$car     <- as.factor(SurveyIncomplete$car)
SurveyIncomplete$zipcode <- as.factor(SurveyIncomplete$zipcode)
# remove label column from prediction/new data - shouldn't be there
SurveyIncomplete$brand <- NULL
str(CompleteResponses)
str(SurveyIncomplete)
# Then create dummy variables. No linear dependencies: FullRank = TRUE
dummies1 <- dummyVars(~., CompleteResponses, fullRank = TRUE)
CompleteResponsesDV <- data.frame(predict(dummies1, CompleteResponses))
names(CompleteResponsesDV)[names(CompleteResponsesDV)=="brand.1"] <- "brand"
CompleteResponsesDV$brand <- as.factor(CompleteResponsesDV$brand)
str(CompleteResponsesDV)
dummies2 <- dummyVars(~., SurveyIncomplete, fullRank = TRUE)
SurveyIncompleteDV <- data.frame(predict(dummies2, SurveyIncomplete))
str(SurveyIncompleteDV)
# Split into training/val set and test set. We will use k-fold cross validation
# when training, so training and validation examples will both be pulled from
# trainSet
inTraining <- createDataPartition(CompleteResponsesDV$brand, p=0.8, list=FALSE)
trainSet <- CompleteResponsesDV[inTraining,]
testSet <- CompleteResponsesDV[-inTraining,]
# scale features
scaleParamsTrain <- preProcess(trainSet[, c(1,2,34)],
method = c("center", "scale"))
print(scaleParamsTrain)
trainSetS <- predict(scaleParamsTrain, trainSet)
testSetS <- predict(scaleParamsTrain, testSet) # scaled with trainSet params
predictionSetS <- predict(scaleParamsTrain, SurveyIncompleteDV) # scaled with trainSet params
regLogisticFitControl <- trainControl(method = "cv", number = 10,
summaryFunction = defaultSummary)
# hyperparameter values to try
modelLookup("regLogistic")
regLogisticGrid <- expand.grid(cost = c(0,0.03,0.1,0.3,1,3,10),
loss = c("L1", "L2_dual", "L2_primal"),
epsilon = c(0.01))
nrow(regLogisticGrid)
startTime <- Sys.time()
regLogisticFit2 <- train(x = CompleteResponses[ ,1:6], y = CompleteResponses[ ,7],
method="regLogistic",
trControl=regLogisticFitControl)
endTime <- Sys.time()
regLogisticFit2RunTime <- endTime - startTime
regLogisticFit2RunTime
